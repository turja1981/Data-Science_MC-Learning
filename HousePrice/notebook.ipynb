{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "First Xgboost",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import model_selection, preprocessing\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn import cross_validation, metrics   #Additional scklearn functions\nfrom sklearn.grid_search import GridSearchCV   #Perforing grid search\n\ncolor = sns.color_palette()\n\n%matplotlib inline\n\npd.options.mode.chained_assignment = None  # default='warn'\npd.set_option('display.max_columns', 500)\nsns.set(style=\"white\", color_codes=True)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train_house_df = pd.read_csv('../input/train.csv')\ntest_house_df = pd.read_csv('../input/test.csv')\nmacro_df = pd.read_csv('../input/macro.csv')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "macro_df.shape",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train_house_df.shape",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "test_house_df.shape",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "target = 'price'\nIDcol = 'id'",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "feature_df = train_house_df.drop(['price_doc'], axis=1 )",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "merge_df = feature_df.append(test_house_df)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "imp_column=['full_sq' , 'life_sq' , 'floor' , 'max_floor' , 'num_room' , 'kitch_sq' , 'state' , 'build_year' , 'material']\nmerge_df['house_age'] = 2019  - merge_df['build_year']\nimp_column.append('house_age')\n\nimp_column",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import Imputer\n\nimp  =  Imputer(missing_values='NaN' ,strategy='median' , axis=1)\n\nmerge_df[imp_column] = imp.fit_transform(merge_df[imp_column])",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "merge_df['log_full_sq'] =  np.log1p(merge_df['full_sq'])\nmerge_df['log_life_sq'] =  np.log1p(merge_df['life_sq'])",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "merge_df['product_type'][merge_df['product_type'].isnull()]='Investment'",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "main_merge_df  =  merge_df[['log_full_sq' , 'log_life_sq' , 'floor' , 'max_floor' , 'num_room' , 'kitch_sq' , 'state' , 'house_age', 'material','product_type' , 'sub_area']]",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import LabelEncoder\n\ndef createDummy(df , var_mod):\n    le = LabelEncoder()\n    #var_mod = ['PROD_ABBR','STATE_ABBR' ]\n    le = LabelEncoder()\n    for i in var_mod:\n        df[i] = le.fit_transform(df[i])\n\n    #One Hot Coding:\n    df = pd.get_dummies(df, columns=var_mod)\n    return df",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "other_column =  merge_df.columns.drop(imp_column)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "cat_columns  = merge_df[other_column].select_dtypes(exclude=['float64' , 'int64']).columns\nnum_columns  = merge_df[other_column].select_dtypes(include=['float64' , 'int64']).columns\nmacro_cat_columns  = macro_df.select_dtypes(exclude=['float64' , 'int64']).columns\n\nmacro_num_columns  = macro_df.select_dtypes(include=['float64' , 'int64']).columns\n",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import Imputer\n\nimp  =  Imputer(missing_values='NaN' ,strategy='median' , axis=1)\n\nmacro_df[macro_num_columns] = imp.fit_transform(macro_df[macro_num_columns])",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "imp  =  Imputer(missing_values='NaN' ,strategy='median' , axis=1)\n\nmerge_df[num_columns] = imp.fit_transform(merge_df[num_columns])",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "main_merge_df[cat_columns] = merge_df[cat_columns]\nmain_merge_df[num_columns] = merge_df[num_columns]",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": null,
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n    \n    if useTrainCV:\n        xgb_param = alg.get_xgb_params()\n        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n            metrics='auc', early_stopping_rounds=early_stopping_rounds, show_progress=False)\n        alg.set_params(n_estimators=cvresult.shape[0])\n    \n    #Fit the algorithm on the data\n    alg.fit(dtrain[predictors], dtrain['price'],eval_metric='auc')\n        \n    #Predict training set:\n    dtrain_predictions = alg.predict(dtrain[predictors])\n    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n        \n    #Print model report:\n    print (\"\\nModel Report\")\n    print (\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['price'].values, dtrain_predictions))\n    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['price'], dtrain_predprob))\n                    \n    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n    feat_imp.plot(kind='bar', title='Feature Importances')\n    plt.ylabel('Feature Importance Score')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Choose all predictors except target & IDcols\n#predictors = [x for x in train.columns if x not in [target, IDcol]]\nxgb1 = XGBClassifier(\n learning_rate =0.1,\n n_estimators=1000,\n max_depth=5,\n min_child_weight=1,\n gamma=0,\n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n nthread=4,\n scale_pos_weight=1,\n seed=27)\nmodelfit(xgb1, train_house_df, test_house_df)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ]
}