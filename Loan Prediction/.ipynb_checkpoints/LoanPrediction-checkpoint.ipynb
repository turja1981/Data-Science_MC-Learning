{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDF = pd.read_csv('train.csv')\n",
    "testDF = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((614, 13), (367, 12))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.shape , testDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID              614\n",
       "Gender               601\n",
       "Married              611\n",
       "Dependents           599\n",
       "Education            614\n",
       "Self_Employed        582\n",
       "ApplicantIncome      614\n",
       "CoapplicantIncome    614\n",
       "LoanAmount           592\n",
       "Loan_Amount_Term     600\n",
       "Credit_History       564\n",
       "Property_Area        614\n",
       "Loan_Status          614\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID              367\n",
       "Gender               356\n",
       "Married              367\n",
       "Dependents           357\n",
       "Education            367\n",
       "Self_Employed        344\n",
       "ApplicantIncome      367\n",
       "CoapplicantIncome    367\n",
       "LoanAmount           362\n",
       "Loan_Amount_Term     361\n",
       "Credit_History       338\n",
       "Property_Area        367\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((614, 14), (367, 13), (981, 14))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF['source']='train'\n",
    "testDF['source']='test'\n",
    "allDF = pd.concat([trainDF, testDF],ignore_index=True)\n",
    "trainDF.shape, testDF.shape, allDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ApplicantIncome        0\n",
       "CoapplicantIncome      0\n",
       "Credit_History         0\n",
       "Dependents             0\n",
       "Education              0\n",
       "Gender                 0\n",
       "LoanAmount             0\n",
       "Loan_Amount_Term       0\n",
       "Loan_ID                0\n",
       "Loan_Status          367\n",
       "Married                0\n",
       "Property_Area          0\n",
       "Self_Employed          0\n",
       "source                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allDF.apply(lambda x: sum(x.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ApplicantIncome        int64\n",
       "CoapplicantIncome    float64\n",
       "Credit_History       float64\n",
       "Dependents            object\n",
       "Education             object\n",
       "Gender                object\n",
       "LoanAmount           float64\n",
       "Loan_Amount_Term     float64\n",
       "Loan_ID               object\n",
       "Loan_Status           object\n",
       "Married               object\n",
       "Property_Area         object\n",
       "Self_Employed         object\n",
       "source                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allDF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ApplicantIncome      752\n",
       "CoapplicantIncome    437\n",
       "Credit_History         2\n",
       "Dependents             4\n",
       "Education              2\n",
       "Gender                 2\n",
       "LoanAmount           233\n",
       "Loan_Amount_Term      12\n",
       "Loan_ID              981\n",
       "Loan_Status            3\n",
       "Married                2\n",
       "Property_Area          3\n",
       "Self_Employed          2\n",
       "source                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allDF.apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>981.000000</td>\n",
       "      <td>981.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>954.000000</td>\n",
       "      <td>961.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5179.795107</td>\n",
       "      <td>1601.916330</td>\n",
       "      <td>0.835920</td>\n",
       "      <td>142.511530</td>\n",
       "      <td>342.201873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5695.104533</td>\n",
       "      <td>2718.772806</td>\n",
       "      <td>0.370553</td>\n",
       "      <td>77.421743</td>\n",
       "      <td>65.100602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2875.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3800.000000</td>\n",
       "      <td>1110.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5516.000000</td>\n",
       "      <td>2365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>81000.000000</td>\n",
       "      <td>41667.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ApplicantIncome  CoapplicantIncome  Credit_History  LoanAmount  \\\n",
       "count       981.000000         981.000000      902.000000  954.000000   \n",
       "mean       5179.795107        1601.916330        0.835920  142.511530   \n",
       "std        5695.104533        2718.772806        0.370553   77.421743   \n",
       "min           0.000000           0.000000        0.000000    9.000000   \n",
       "25%        2875.000000           0.000000        1.000000  100.000000   \n",
       "50%        3800.000000        1110.000000        1.000000  126.000000   \n",
       "75%        5516.000000        2365.000000        1.000000  162.000000   \n",
       "max       81000.000000       41667.000000        1.000000  700.000000   \n",
       "\n",
       "       Loan_Amount_Term  \n",
       "count        961.000000  \n",
       "mean         342.201873  \n",
       "std           65.100602  \n",
       "min            6.000000  \n",
       "25%          360.000000  \n",
       "50%          360.000000  \n",
       "75%          360.000000  \n",
       "max          480.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get a boolean variable specifying missing Item_Weight values\n",
    "miss_data = allDF['Credit_History'].isnull() \n",
    "\n",
    "#Impute data and check #missing values before and after imputation to confirm\n",
    "#print 'Orignal #missing: %d'% sum(miss_bool)\n",
    "allDF.loc[miss_data,'Credit_History'] = 1.000000\n",
    "#print 'Final #missing: %d'% sum(data['Item_Weight'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allDF['Gender'] = allDF['Gender'].fillna( allDF['Gender'].dropna().mode().values[0] )\n",
    "allDF['Married'] = allDF['Married'].fillna( allDF['Married'].dropna().mode().values[0] )\n",
    "allDF['Dependents'] = allDF['Dependents'].fillna( allDF['Dependents'].dropna().mode().values[0] )\n",
    "allDF['Self_Employed'] = allDF['Self_Employed'].fillna( allDF['Self_Employed'].dropna().mode().values[0] )\n",
    "allDF['LoanAmount'] = allDF['LoanAmount'].fillna( allDF['LoanAmount'].dropna().mean() )\n",
    "allDF['Loan_Amount_Term'] = allDF['Loan_Amount_Term'].fillna( allDF['Loan_Amount_Term'].dropna().mode().values[0] )\n",
    "allDF['Credit_History'] = allDF['Credit_History'].fillna( allDF['Credit_History'].dropna().mode().values[0] )\n",
    "allDF['Dependents'] = allDF['Dependents'].str.rstrip('+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y    422\n",
       "N    192\n",
       "Name: Loan_Status, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allDF['Loan_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert NA to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-cf5e2a5423b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mallDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Gender'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mallDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Gender'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Female'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Male'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mallDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Married'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mallDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Married'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'No'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Yes'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mallDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Education'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mallDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Education'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Not Graduate'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Graduate'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mallDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Self_Employed'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mallDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Self_Employed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'No'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Yes'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;31m#allDF['Loan_Status'][['source']='train'] = allDF['Loan_Status'].map({'N':0, 'Y':1}).astype(np.int)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, raise_on_error, **kwargs)\u001b[0m\n\u001b[1;32m   3052\u001b[0m         \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3053\u001b[0m         new_data = self._data.astype(dtype=dtype, copy=copy,\n\u001b[0;32m-> 3054\u001b[0;31m                                      raise_on_error=raise_on_error, **kwargs)\n\u001b[0m\u001b[1;32m   3055\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3056\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m   3187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3189\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'astype'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3191\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m   3054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mgr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3056\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3057\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, raise_on_error, values, **kwargs)\u001b[0m\n\u001b[1;32m    459\u001b[0m                **kwargs):\n\u001b[1;32m    460\u001b[0m         return self._astype(dtype, copy=copy, raise_on_error=raise_on_error,\n\u001b[0;32m--> 461\u001b[0;31m                             values=values, **kwargs)\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     def _astype(self, dtype, copy=False, raise_on_error=True, values=None,\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_astype\u001b[0;34m(self, dtype, copy, raise_on_error, values, klass, mgr, **kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                 \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_astype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\types\\cast.py\u001b[0m in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot convert NA to integer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[1;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert NA to integer"
     ]
    }
   ],
   "source": [
    "allDF['Gender'] = allDF['Gender'].map({'Female':0,'Male':1}).astype(np.int)\n",
    "allDF['Married'] = allDF['Married'].map({'No':0, 'Yes':1}).astype(np.int)\n",
    "allDF['Education'] = allDF['Education'].map({'Not Graduate':0, 'Graduate':1}).astype(np.int)\n",
    "allDF['Self_Employed'] = allDF['Self_Employed'].map({'No':0, 'Yes':1}).astype(np.int)\n",
    "allDF['Dependents'] = allDF['Dependents'].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "#New variable for outlet\n",
    "\n",
    "var_mod = ['Dependents','Education','Gender', 'Married' , 'Property_Area' , 'Self_Employed']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    allDF[i] = le.fit_transform(allDF[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allDF_Dummy = pd.get_dummies(allDF, columns=['Dependents','Education','Gender','Married' ,'Property_Area' , 'Self_Employed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    862\n",
       "1    119\n",
       "Name: Self_Employed, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allDF['Self_Employed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = allDF.loc[allDF['source']==\"train\"]\n",
    "test_data = allDF.loc[allDF['source']==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((614, 14), (367, 14))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape , test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y    422\n",
       "N    192\n",
       "Name: Loan_Status, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Loan_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.get_dummies(train_data, columns=['Loan_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def modelfitClassification(alg, dtrain, dvalidation , dtest, predictors, target, IDcol, filename):\n",
    "    #Fit the algorithm on the data\n",
    "    \n",
    "    print('predictors '+str(predictors))\n",
    "        \n",
    "        \n",
    "    alg.fit(dtrain[predictors], dtrain[target])\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "\n",
    "    #Perform cross-validation:\n",
    "    cv_score = cross_val_score(alg, dtrain[predictors], dtrain[target], cv=5, scoring='accuracy')\n",
    "    cv_score = np.sqrt(np.abs( cv_score))\n",
    "    \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"RMSE : %.4g\" % np.sqrt(metrics.accuracy_score(dtrain[target].values, dtrain_predictions)))\n",
    "    print (\"CV Score : Mean - %.4g | Std - %.4g | Min - %.4g | Max - %.4g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "\n",
    "    #Model Accuracy on validation data:\n",
    "    \n",
    "    dvalidation_predictions = alg.predict(dvalidation[predictors])\n",
    "    print (\"\\nValidation Model Report\")\n",
    "    print (\"RMSE : %.4g\" % np.sqrt(metrics.accuracy_score(dvalidation[target].values, dvalidation_predictions)))\n",
    "    \n",
    "    \n",
    "    #Predict on testing data:\n",
    "    \n",
    "    dtest_predictions = alg.predict(dtest[predictors])\n",
    "    dtest['Loan_Status'] = dtest_predictions\n",
    "    #Export submission file:\n",
    "    IDcol.append(\"Loan_Status\")\n",
    "    submission = pd.DataFrame({ x: dtest[x] for x in IDcol})\n",
    "    submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, validation_data = train_test_split(train_data, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((491, 14), (123, 14))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape , validation_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictors ['ApplicantIncome', 'CoapplicantIncome', 'Credit_History', 'Dependents', 'Education', 'Gender', 'LoanAmount', 'Loan_Amount_Term', 'Married', 'Property_Area', 'Self_Employed']\n",
      "\n",
      "Model Report\n",
      "RMSE : 0.9037\n",
      "CV Score : Mean - 0.9025 | Std - 0.01188 | Min - 0.8864 | Max - 0.9203\n",
      "\n",
      "Validation Model Report\n",
      "RMSE : 0.8926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "target = 'Loan_Status'\n",
    "IDcol = ['Loan_ID']\n",
    "removeColumn = ['source']\n",
    "predictors = [x for x in train_data.columns if x not in [target]+IDcol+removeColumn]\n",
    "# print predictors\n",
    "alg1 = LogisticRegression()\n",
    "modelfitClassification(alg1, train_data, validation_data , test_data, predictors, target, IDcol, 'linearLoan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "target = 'Loan_Status'\n",
    "IDcol = ['Loan_ID']\n",
    "removeColumn = ['source']\n",
    "predictors = [x for x in train_data.columns if x not in [target]+IDcol+removeColumn]\n",
    "# print predictors\n",
    "alg1 = LogisticRegression()\n",
    "modelfitClassification(alg1, train_data, validation_data , test_data, predictors, target, IDcol, 'linearLoan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "def modelfitGridSearchClassification(alg, dtrain, dvalidation , dtest, predictors, target, IDcol, filename, tuned_parameters):\n",
    "    #Fit the algorithm on the data\n",
    "    \n",
    "    print('predictors '+str(predictors))\n",
    "        \n",
    "        \n",
    "    clf = GridSearchCV(alg, tuned_parameters, cv=5, scoring='accuracy')\n",
    "    \n",
    "    clf.fit(dtrain[predictors], dtrain[target])\n",
    "    \n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(clf.best_estimator_)\n",
    "    \n",
    "    print(\"Best Score\"+str(clf.best_score_))\n",
    "    \n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = clf.predict(dtrain[predictors])\n",
    "\n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"RMSE : %.4g\" % np.sqrt(metrics.accuracy_score(dtrain[target].values, dtrain_predictions)))\n",
    "    \n",
    "\n",
    "    #Model Accuracy on validation data:\n",
    "    \n",
    "    dvalidation_predictions = clf.predict(dvalidation[predictors])\n",
    "    print (\"\\nValidation Model Report\")\n",
    "    print (\"RMSE : %.4g\" % np.sqrt(metrics.accuracy_score(dvalidation[target].values, dvalidation_predictions)))\n",
    "    \n",
    "    \n",
    "    #Predict on testing data:\n",
    "    \n",
    "    dtest_predictions = clf.predict(dtest[predictors])\n",
    "    dtest['Loan_Status'] = dtest_predictions\n",
    "    #Export submission file:\n",
    "    IDcol.append(\"Loan_Status\")\n",
    "    submission = pd.DataFrame({ x: dtest[x] for x in IDcol})\n",
    "    submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictors ['ApplicantIncome', 'CoapplicantIncome', 'Credit_History', 'Dependents', 'Education', 'Gender', 'LoanAmount', 'Loan_Amount_Term', 'Married', 'Property_Area', 'Self_Employed']\n",
      "Best parameters set found on development set:\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=5, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=4, min_samples_split=150,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "Best Score0.7983706720977597\n",
      "\n",
      "Model Report\n",
      "RMSE : 0.9048\n",
      "\n",
      "Validation Model Report\n",
      "RMSE : 0.8926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "target = 'Loan_Status'\n",
    "IDcol = ['Loan_ID']\n",
    "removeColumn = ['source']\n",
    "predictors = [x for x in train_data.columns if x not in [target]+IDcol+removeColumn]\n",
    "# print predictors\n",
    "\n",
    "param_grid = {\"criterion\": [\"entropy\"],\n",
    "              \"min_samples_split\": [10 , 20 ,50 , 100 , 150],\n",
    "              \"max_depth\": [ 5 ,10 , 15],\n",
    "              \"min_samples_leaf\": [ 2 ,4 , 5],\n",
    "              \"max_leaf_nodes\": [ 5, 10 , 20 ,25],\n",
    "             # \"max_features\" :['auto']\n",
    "              }\n",
    "\n",
    "alg3 = DecisionTreeClassifier()\n",
    "modelfitGridSearchClassification(alg3, train_data, validation_data , test_data, predictors, target, IDcol, 'Decision.csv' , param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictors ['ApplicantIncome', 'CoapplicantIncome', 'Credit_History', 'Dependents', 'Education', 'Gender', 'LoanAmount', 'Loan_Amount_Term', 'Married', 'Property_Area', 'Self_Employed']\n",
      "Best parameters set found on development set:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=50, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "Best Score0.8105906313645621\n",
      "\n",
      "Model Report\n",
      "RMSE : 0.9048\n",
      "\n",
      "Validation Model Report\n",
      "RMSE : 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "target = 'Loan_Status'\n",
    "IDcol = ['Loan_ID']\n",
    "removeColumn = ['source']\n",
    "predictors = [x for x in train_data.columns if x not in [target]+IDcol+removeColumn]\n",
    "# print predictors\n",
    "\n",
    "param_grid = {\"criterion\": [\"entropy\"],\n",
    "              \"min_samples_split\": [2 , 5 , 10,50]\n",
    "              #\"max_depth\": [2, 5 ,10 , 15],\n",
    "              #\"min_samples_leaf\": [ 2 ,4 , 5],\n",
    "              #\"max_leaf_nodes\": [ 5, 10 , 20 ,25],\n",
    "              #\"max_features\" :['auto' , 3],\n",
    "              #\"n_estimators\":[10,50,100]\n",
    "              }\n",
    "\n",
    "alg3 = RandomForestClassifier()\n",
    "modelfitGridSearchClassification(alg3, train_data, validation_data , test_data, predictors, target, IDcol, 'RandomForest.csv' , param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictors ['ApplicantIncome', 'CoapplicantIncome', 'Credit_History', 'Dependents', 'Education', 'Gender', 'LoanAmount', 'Loan_Amount_Term', 'Married', 'Property_Area', 'Self_Employed']\n",
      "Best parameters set found on development set:\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=1, random_state=6)\n",
      "Best Score0.8126272912423625\n",
      "\n",
      "Model Report\n",
      "RMSE : 0.9015\n",
      "\n",
      "Validation Model Report\n",
      "RMSE : 0.8926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "target = 'Loan_Status'\n",
    "IDcol = ['Loan_ID']\n",
    "removeColumn = ['source']\n",
    "predictors = [x for x in train_data.columns if x not in [target]+IDcol+removeColumn]\n",
    "# print predictors\n",
    "\n",
    "param_grid = {\"n_estimators\": [1],\n",
    "              #\"base_estimator\": ['tree' ],\n",
    "              #\"learning_rate\": [0.2],\n",
    "              #\"min_samples_leaf\": [ 2 ,4 , 5],\n",
    "              #\"max_leaf_nodes\": [ 5, 10 , 20 ,25],\n",
    "              #\"max_features\" :['auto' , 3]\n",
    "              \"random_state\":[6]\n",
    "              }\n",
    "\n",
    "alg3 = AdaBoostClassifier()\n",
    "modelfitGridSearchClassification(alg3, train_data, validation_data , test_data, predictors, target, IDcol, 'AdaBoost.csv' , param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
